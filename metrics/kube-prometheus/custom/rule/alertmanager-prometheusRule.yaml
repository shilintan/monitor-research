apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    app.kubernetes.io/component: alert-router
    app.kubernetes.io/instance: main
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/part-of: kube-prometheus
    app.kubernetes.io/version: 0.25.0
    prometheus: k8s
    role: alert-rules
  name: alertmanager-main-rules
  namespace: monitoring
spec:
  groups:
  - name: alertmanager.rules
    rules:
    - alert: AlertmanagerFailedReload
      annotations:
        description: "未能加载 {{ $labels.namespace }}/{{$labels.pod}} 的配置。"
#        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagerfailedreload
        summary: 重新加载 Alertmanager 配置失败。
      expr: |
        max_over_time(alertmanager_config_last_reload_successful{job="alertmanager-main",namespace="monitoring"}[5m]) < 1
      for: 10m
      labels:
        severity: critical
    - alert: AlertmanagerMembersInconsistent
      annotations:
        description: "Alertmanager {{ $labels.namespace }}/{{ $labels.pod}} 仅找到 {{$labels.job}} 集群的 {{ $value }} 成员。"
#        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagermembersinconsistent
        summary: Alertmanager 集群的成员尚未找到所有其他集群成员。
      expr: |
        # Without max_over_time, failed scrapes could create false negatives, see
        # https://www.robustperception.io/alerting-on-gauges-in-prometheus-2-0 for details.
          max_over_time(alertmanager_cluster_members{job="alertmanager-main",namespace="monitoring"}[5m])
        < on (namespace,service) group_left count by (namespace,service) (max_over_time(alertmanager_cluster_members{job="alertmanager-main",namespace="monitoring"}[5m]))
      for: 15m
      labels:
        severity: critical
    - alert: AlertmanagerFailedToSendAlerts
      annotations:
        description: "Alertmanager {{ $labels.namespace }}/{{ $labels.pod}} 未能将 {{ $value|humanizePercentage }} 条通知发送到 {{ $labels.integration }}。"
#        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagerfailedtosendalerts
        summary: Alertmanager 实例发送通知失败。
      expr: |
        (
          rate(alertmanager_notifications_failed_total{job="alertmanager-main",namespace="monitoring"}[5m])
        /
          rate(alertmanager_notifications_total{job="alertmanager-main",namespace="monitoring"}[5m])
        )
        > 0.01
      for: 5m
      labels:
        severity: warning
    - alert: AlertmanagerClusterFailedToSendAlerts
      annotations:
        description: "从 {{$labels.job}} 集群中的任何实例发送到 {{ $labels.integration }} 的最小通知失败率为 {{ $value|humanizePercentage}}。"
#        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagerclusterfailedtosendalerts
        summary: 集群中的所有 Alertmanager 实例均无法向关键集成发送通知。
      expr: |
        min by (namespace,service, integration) (
          rate(alertmanager_notifications_failed_total{job="alertmanager-main",namespace="monitoring", integration=~`.*`}[5m])
        /
          rate(alertmanager_notifications_total{job="alertmanager-main",namespace="monitoring", integration=~`.*`}[5m])
        )
        > 0.01
      for: 5m
      labels:
        severity: critical
    - alert: AlertmanagerClusterFailedToSendAlerts
      annotations:
        description: "从 {{$labels.job}} 集群中的任何实例发送到 {{ $labels.integration}} 的最小通知失败率为 {{ $value| humanizePercentage }}。"
#        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagerclusterfailedtosendalerts
        summary: 集群中的所有 Alertmanager 实例均无法向非关键集成发送通知。
      expr: |
        min by (namespace,service, integration) (
          rate(alertmanager_notifications_failed_total{job="alertmanager-main",namespace="monitoring", integration!~`.*`}[5m])
        /
          rate(alertmanager_notifications_total{job="alertmanager-main",namespace="monitoring", integration!~`.*`}[5m])
        )
        > 0.01
      for: 5m
      labels:
        severity: warning
    - alert: AlertmanagerConfigInconsistent
      annotations:
        description: "{{$labels.job}} 集群中的 Alertmanager 实例具有不同的配置。"
#        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagerconfiginconsistent
        summary: 同一集群内的Alertmanager实例具有不同的配置。
      expr: |
        count by (namespace,service) (
          count_values by (namespace,service) ("config_hash", alertmanager_config_hash{job="alertmanager-main",namespace="monitoring"})
        )
        != 1
      for: 20m
      labels:
        severity: critical
    - alert: AlertmanagerClusterDown
      annotations:
        description: "{{$labels.job}} 集群内的 {{ $value| humanizePercentage }} 的 Alertmanager 实例的运行时间不到过去 5m 的一半。"
#        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagerclusterdown
        summary: 同一集群中一半或更多的 Alertmanager 实例已关闭。
      expr: |
        (
          count by (namespace,service) (
            avg_over_time(up{job="alertmanager-main",namespace="monitoring"}[5m]) < 0.5
          )
        /
          count by (namespace,service) (
            up{job="alertmanager-main",namespace="monitoring"}
          )
        )
        >= 0.5
      for: 5m
      labels:
        severity: critical
    - alert: AlertmanagerClusterCrashlooping
      annotations:
        description: "{{$labels.job}} 集群中的 {{ $value| humanizePercentage }} 的 Alertmanager 实例在过去 10 分钟内至少重新启动了 5 次。"
#        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagerclustercrashlooping
        summary: 同一集群中一半或更多的 Alertmanager 实例发生崩溃循环。
      expr: |
        (
          count by (namespace,service) (
            changes(process_start_time_seconds{job="alertmanager-main",namespace="monitoring"}[10m]) > 4
          )
        /
          count by (namespace,service) (
            up{job="alertmanager-main",namespace="monitoring"}
          )
        )
        >= 0.5
      for: 5m
      labels:
        severity: critical
